# Year-3-Project

EmotionAI: Convolutional Neural Network based Multimodal Dimensional Emotion Recognition
Proposer: Yona Falinie A. Gaus (with Toby Breckon)

Subject Areas: Artificial Intelligence, Computer Vision, Image Processing, Affective Computing

Description: 

Automatic emotion recognition is a crucial component to improve natural human-computer interactions. Two types of problems are usually considered: emotion recognition among discrete categories or emotion prediction into continuous dimensions. Both problem try to take advantages of signal processing methods to automatically analyse emotions in accordance with emotional representation models developed by psychologists. On one hand, classification methods are used for emotion recognition , generally the discrete categories such as happiness, sadness, surpirse, anger, disgust, fear. On the other hand, regression methods are used to infer the emotional state, which is defined as a vector of continuous emotional dimensions such as valence, arousal, power or expectancy and sentiment analysis.

Literature shows an excellent performance of emotion recognition is achieved with in-the-lab data, but the challenge remains opened for in-the-wild data. Indeed, in-the-wild data implies additional noise that cannot be tackled by algorithms trained on laboratory-controlled data. Thus, this project focuses on emotion analysis in in-the-wild data, which mimicks real-world condition. Specifically, the goal is to predict the level of three emotional dimensions (arousal, valence and likability) time-continuously in a cross-cultural setup (German => Hungarian) from audio-visual recordings of dyadic interactions (SEWA corpus). This project would look to implement multiple modalities (video and audio) efficient deep learning features and full use of LSTM network to capture the long-term temporal information. Training and Evaluation could be carried out using cross-cultural audio-visual dataset which is captured in the real-life dyadic human-human video chat scenarios.

Requirements: Students must have taken or be taking Image Processing (L2), Computer Vision (L3 + L4 SSA) and ideally Machine Learning / Deep Learning (L3/L4 CC) and be comfortable with (or able to readily pickup) C/C++ to be able to leverage existing implementations. A familiarity with OpenCV, communications & networking and the linux operating system is of benefit.

Keywords: computer vision, image processing, thermal imaging, tracking, hardware control

Academic background reading:

AVEC 2018 Workshop and Challenge: Bipolar Disorder and Cross-Cultural Affect Recognition
A Multi-modal Multi-cultural Dimensional Continues Emotion Recognition in Dyadic Interactions
Strength Modelling for Real-World Automatic Continuous Affect Recognition from Audiovisual Signals
Multi-Modal Audio, Video and Physiological Sensor Learning for Continuous Emotion Prediction
Anticipated Outcome: a working software demonstrator and technical evaluation of the state of the art in continuous emotion recognition with potential to extend to publishable novel contributions in this research area.
